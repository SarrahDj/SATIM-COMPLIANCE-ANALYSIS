{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Compliance Analyzer System Documentation\n",
        "\n",
        "## Overview\n",
        "This system performs automated compliance analysis by comparing the internal security policy documents against regulatory requirements using natural language processing and machine learning techniques.\n",
        "\n",
        "\n",
        "### 1. DocumentProcessor\n",
        "Extracts text content from various document formats for analysis.\n",
        "\n",
        "**Features**:\n",
        "- Supports multiple file formats (.pdf, .docx, .txt, .html)\n",
        "- Error handling for corrupted or unreadable files\n",
        "- Metadata extraction including word count and file paths\n",
        "\n"
      ],
      "metadata": {
        "id": "_x4a8zQeadRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import PyPDF2\n",
        "import docx\n",
        "from bs4 import BeautifulSoup\n",
        "from collections import defaultdict\n",
        "import spacy\n",
        "import re\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import faiss\n",
        "import pickle\n",
        "from typing import List, Dict, Optional\n",
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import json\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "2eaaRmcE73Hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DocumentProcessor:\n",
        "    def __init__(self):\n",
        "        self.supported_formats = ['.pdf', '.docx', '.txt', '.html']\n",
        "\n",
        "    def extract_text_from_pdf(self, file_path: Path) -> str:\n",
        "        \"\"\"Extract text from PDF files\"\"\"\n",
        "        text = \"\"\n",
        "        try:\n",
        "            with open(file_path, 'rb') as file:\n",
        "                pdf_reader = PyPDF2.PdfReader(file)\n",
        "                for page in pdf_reader.pages:\n",
        "                    text += page.extract_text()\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting text from PDF {file_path}: {e}\")\n",
        "        return text\n",
        "\n",
        "    def extract_text_from_docx(self, file_path: Path) -> str:\n",
        "        \"\"\"Extract text from DOCX files\"\"\"\n",
        "        text = \"\"\n",
        "        try:\n",
        "            doc = docx.Document(file_path)\n",
        "            for paragraph in doc.paragraphs:\n",
        "                text += paragraph.text + \"\\n\"\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting text from DOCX {file_path}: {e}\")\n",
        "        return text\n",
        "\n",
        "    def process_documents(self, folder_path: str, doc_type: str = \"policy\") -> List[Dict]:\n",
        "        \"\"\"Process all documents in a folder\"\"\"\n",
        "        documents = []\n",
        "        for file_path in Path(folder_path).rglob(\"*\"):\n",
        "            if file_path.suffix.lower() in self.supported_formats:\n",
        "                try:\n",
        "                    text = \"\"\n",
        "                    if file_path.suffix.lower() == '.pdf':\n",
        "                        text = self.extract_text_from_pdf(file_path)\n",
        "                    elif file_path.suffix.lower() == '.docx':\n",
        "                        text = self.extract_text_from_docx(file_path)\n",
        "                    elif file_path.suffix.lower() == '.html':\n",
        "                        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                            soup = BeautifulSoup(f.read(), 'html.parser')\n",
        "                            text = soup.get_text()\n",
        "                    else: # .txt or unsupported with fallback to read_text\n",
        "                        text = file_path.read_text(encoding='utf-8')\n",
        "\n",
        "                    if text.strip(): # Only add documents with extracted text\n",
        "                        documents.append({\n",
        "                            'filename': file_path.name,\n",
        "                            'path': str(file_path),\n",
        "                            'text': text,\n",
        "                            'type': doc_type,\n",
        "                            'word_count': len(text.split())\n",
        "                        })\n",
        "                    else:\n",
        "                        print(f\"Warning: No text extracted from {file_path.name}.\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {file_path}: {e}\")\n",
        "\n",
        "        return documents"
      ],
      "metadata": {
        "id": "mGiCh_Y47_Sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. TextProcessor\n",
        " Processes and analyzes extracted text to prepare it for similarity comparison.\n",
        "\n",
        "**Features**:\n",
        "- Uses spaCy for advanced natural language processing\n",
        "- Implements overlapping chunking strategy to maintain context\n",
        "- Pattern-based requirement extraction using regex for compliance language\n"
      ],
      "metadata": {
        "id": "bcY2N3jEahb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextProcessor:\n",
        "    def __init__(self):\n",
        "        # Ensure 'en_core_web_sm' is downloaded: python -m spacy download en_core_web_sm\n",
        "        try:\n",
        "            self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "        except OSError:\n",
        "            print(\"Downloading spacy model 'en_core_web_sm'...\")\n",
        "            spacy.cli.download(\"en_core_web_sm\")\n",
        "            self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "        self.sentence_model = SentenceTransformer('all-MiniLM-L6-v2') # This model is not used if EmbeddingGenerator is initialized with a different one.\n",
        "\n",
        "    def clean_text(self, text: str) -> str:\n",
        "        \"\"\"Clean and normalize text\"\"\"\n",
        "        # Remove extra whitespace and special characters\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        # Keep basic punctuation (periods, commas, semicolons, colons, exclamation marks, question marks)\n",
        "        text = re.sub(r'[^\\w\\s\\.\\,\\;\\:\\!\\?]', '', text)\n",
        "        return text.strip()\n",
        "\n",
        "    def chunk_document(self, text: str, chunk_size: int = 500, overlap: int = 50) -> List[str]:\n",
        "        \"\"\"Split document into overlapping chunks\"\"\"\n",
        "        words = text.split()\n",
        "        chunks = []\n",
        "\n",
        "        if not words:\n",
        "            return []\n",
        "\n",
        "        for i in range(0, len(words), chunk_size - overlap):\n",
        "            chunk = ' '.join(words[i:i + chunk_size])\n",
        "            # Minimum chunk size to ensure meaningful content\n",
        "            if len(chunk.split()) > 50:\n",
        "                chunks.append(chunk)\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    def extract_requirements(self, text: str) -> List[str]:\n",
        "        \"\"\"Extract requirement-like sentences using NLP\"\"\"\n",
        "        doc = self.nlp(text)\n",
        "        requirements = []\n",
        "\n",
        "        # Look for sentences with modal verbs (shall, must, should) or compliance-related terms\n",
        "        requirement_patterns = [\n",
        "            r'\\b(shall|must|should|required|mandatory|obligated|need to)\\b',\n",
        "            r'\\b(compliance|conform|adhere|abide by|in accordance with)\\b',\n",
        "            r'\\b(prohibited|forbidden|not permitted|unlawful)\\b',\n",
        "            r'\\b(ensure that|it is essential that)\\b'\n",
        "        ]\n",
        "\n",
        "        for sent in doc.sents:\n",
        "            sent_text = sent.text.strip()\n",
        "            # Ensure the sentence is not too short to be meaningful\n",
        "            if len(sent_text.split()) > 5 and any(re.search(pattern, sent_text, re.IGNORECASE)\n",
        "                                                   for pattern in requirement_patterns):\n",
        "                requirements.append(sent_text)\n",
        "\n",
        "        return requirements"
      ],
      "metadata": {
        "id": "jWKbGxSQ8Dx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 3. EmbeddingGenerator\n",
        " Converts text into numerical vector representations for semantic similarity analysis.\n",
        "\n",
        "**Features**:\n",
        "- Uses advanced sentence transformer models (all-mpnet-base-v2)\n",
        "- GPU acceleration when available\n",
        "- Batch processing for efficiency\n",
        "- Hierarchical indexing with FAISS for scalable similarity search\n"
      ],
      "metadata": {
        "id": "WUrnOzSJ8viN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingGenerator:\n",
        "    def __init__(self, model_name: str = 'all-mpnet-base-v2'):\n",
        "        \"\"\"\n",
        "        Initialize with a more powerful sentence transformer model\n",
        "        Options: 'all-mpnet-base-v2', 'all-distilroberta-v1', 'multi-qa-mpnet-base-dot-v1'\n",
        "        \"\"\"\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "        self.dimension = self.model.get_sentence_embedding_dimension()\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    def generate_contextual_embeddings(self, texts: List[str],\n",
        "                                       batch_size: int = 32) -> np.ndarray:\n",
        "        \"\"\"Generate embeddings with better batching and normalization\"\"\"\n",
        "        if not texts:\n",
        "            return np.array([])\n",
        "\n",
        "        # Filter empty texts\n",
        "        valid_texts = [text for text in texts if text and text.strip()]\n",
        "        if not valid_texts:\n",
        "            return np.array([])\n",
        "\n",
        "        # Generate embeddings in batches\n",
        "        embeddings = self.model.encode(\n",
        "            valid_texts,\n",
        "            batch_size=batch_size,\n",
        "            convert_to_tensor=False,\n",
        "            normalize_embeddings=True,  # L2 normalization for better cosine similarity\n",
        "            show_progress_bar=len(valid_texts) > 100\n",
        "        )\n",
        "\n",
        "        return embeddings.astype(np.float32)\n",
        "\n",
        "    def create_hierarchical_index(self, embeddings: np.ndarray,\n",
        "                                  text_metadata: List[Dict]) -> Dict:\n",
        "        \"\"\"Create hierarchical FAISS index with metadata\"\"\"\n",
        "        if embeddings.size == 0:\n",
        "            return {'index': None, 'embeddings': np.array([]), 'metadata': [], 'clusters': [], 'dimension': self.dimension}\n",
        "\n",
        "        # Create main index\n",
        "        index = faiss.IndexFlatIP(self.dimension)\n",
        "        index.add(embeddings)\n",
        "\n",
        "        # Create clustering for better organization (requires sklearn)\n",
        "        try:\n",
        "            clusters = self._create_semantic_clusters(embeddings, text_metadata)\n",
        "        except ImportError:\n",
        "            print(\"Scikit-learn not found. Skipping semantic clustering.\")\n",
        "            clusters = []\n",
        "\n",
        "        return {\n",
        "            'index': index,\n",
        "            'embeddings': embeddings,\n",
        "            'metadata': text_metadata,\n",
        "            'clusters': clusters,\n",
        "            'dimension': self.dimension\n",
        "        }\n",
        "\n",
        "    def _create_semantic_clusters(self, embeddings: np.ndarray,\n",
        "                                  metadata: List[Dict], n_clusters: int = None) -> List[Dict]:\n",
        "        \"\"\"Create semantic clusters for better organization\"\"\"\n",
        "        try:\n",
        "            from sklearn.cluster import KMeans\n",
        "        except ImportError:\n",
        "            raise ImportError(\"scikit-learn is not installed. Please install it to use clustering.\")\n",
        "\n",
        "        if len(embeddings) < 2:  # Need at least 2 items to cluster meaningfully\n",
        "            return [{'cluster_id': 0, 'items': list(range(len(embeddings))), 'centroid': None, 'size': len(embeddings)}]\n",
        "\n",
        "        if n_clusters is None:\n",
        "            # Adaptive clustering: min 2, max 20, or 10% of items, whichever is appropriate\n",
        "            n_clusters = min(max(2, len(embeddings) // 10), 20)\n",
        "            if n_clusters > len(embeddings): # Prevent n_clusters from being greater than number of samples\n",
        "                n_clusters = len(embeddings)\n",
        "\n",
        "        # Handle cases where n_clusters might still be too large for the number of samples\n",
        "        if n_clusters < 1:\n",
        "            return [{'cluster_id': 0, 'items': list(range(len(embeddings))), 'centroid': None, 'size': len(embeddings)}]\n",
        "\n",
        "        # Ensure n_init is appropriate for the number of samples\n",
        "        n_init_val = min(10, max(1, n_clusters))\n",
        "\n",
        "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=n_init_val)\n",
        "        cluster_labels = kmeans.fit_predict(embeddings)\n",
        "\n",
        "        clusters = []\n",
        "        for i in range(n_clusters):\n",
        "            cluster_items = [idx for idx, label in enumerate(cluster_labels) if label == i]\n",
        "            if cluster_items:  # Only add non-empty clusters\n",
        "                clusters.append({\n",
        "                    'cluster_id': i,\n",
        "                    'items': cluster_items,\n",
        "                    'centroid': kmeans.cluster_centers_[i].tolist(), # Convert to list for JSON serialization\n",
        "                    'size': len(cluster_items)\n",
        "                })\n",
        "        return clusters"
      ],
      "metadata": {
        "id": "mgTtfp9g8M2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. SimilarityAnalyzer\n",
        " Performs comprehensive similarity analysis between policy and regulatory content.\n",
        "\n",
        "\n",
        "**Analysis Features**:\n",
        "- **Multi-threshold Analysis**: Uses different similarity thresholds (exact match: 0.85, strong coverage: 0.70, partial coverage: 0.50, weak coverage: 0.30)\n",
        "- **Coverage Analysis**: Calculates what percentage of regulatory requirements are covered by policies\n",
        "- **Gap Identification**: Categorizes gaps as critical, significant, or minor based on similarity scores\n",
        "- **Compliance Scoring**: Generates overall compliance scores with letter grades (A-F)\n",
        "- **Semantic Clustering**: Groups related requirements and policies for better organization\n"
      ],
      "metadata": {
        "id": "vREZOPUz86zr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimilarityAnalyzer:\n",
        "    def __init__(self, embedding_generator: EmbeddingGenerator):\n",
        "        self.embedding_gen = embedding_generator\n",
        "        # Multiple thresholds for different analysis levels\n",
        "        self.thresholds = {\n",
        "            'exact_match': 0.85,       # Very high similarity\n",
        "            'strong_coverage': 0.70,   # Good coverage\n",
        "            'partial_coverage': 0.50,  # Some coverage\n",
        "            'weak_coverage': 0.30      # Minimal coverage\n",
        "        }\n",
        "\n",
        "    def comprehensive_similarity_analysis(self,\n",
        "                                          policy_data: Dict,\n",
        "                                          regulatory_data: Dict) -> Dict:\n",
        "        \"\"\"Perform comprehensive similarity analysis\"\"\"\n",
        "\n",
        "        # Extract embeddings and metadata\n",
        "        policy_embeddings = policy_data.get('embeddings', np.array([]))\n",
        "        regulatory_embeddings = regulatory_data.get('embeddings', np.array([]))\n",
        "        policy_metadata = policy_data.get('metadata', [])\n",
        "        regulatory_metadata = regulatory_data.get('metadata', [])\n",
        "\n",
        "        if regulatory_embeddings.size == 0 or policy_embeddings.size == 0 or \\\n",
        "           len(regulatory_metadata) == 0 or len(policy_metadata) == 0:\n",
        "            print(\"Warning: Missing or empty embeddings/metadata for similarity analysis.\")\n",
        "            return {\n",
        "                'similarity_matrix': np.array([[]]),\n",
        "                'detailed_matches': [],\n",
        "                'coverage_analysis': {},\n",
        "                'gap_analysis': {\n",
        "                    'critical_gaps': [], 'significant_gaps': [], 'minor_gaps': [],\n",
        "                    'gap_categories': defaultdict(list), 'recommendations': []\n",
        "                },\n",
        "                'semantic_clusters': {},\n",
        "                'compliance_score': {'overall_score': 0.0, 'grade': 'F', 'metrics': {}}\n",
        "            }\n",
        "\n",
        "        # Calculate similarity matrices\n",
        "        similarity_matrix = cosine_similarity(regulatory_embeddings, policy_embeddings)\n",
        "\n",
        "        # Perform multi-level analysis\n",
        "        results = {\n",
        "            'similarity_matrix': similarity_matrix,\n",
        "            'detailed_matches': self._find_detailed_matches(\n",
        "                regulatory_metadata, policy_metadata, similarity_matrix\n",
        "            ),\n",
        "            'coverage_analysis': self._analyze_coverage(\n",
        "                regulatory_metadata, policy_metadata, similarity_matrix\n",
        "            ),\n",
        "            'gap_analysis': self._perform_gap_analysis(\n",
        "                regulatory_metadata, policy_metadata, similarity_matrix\n",
        "            ),\n",
        "            'semantic_clusters': self._analyze_semantic_clusters(\n",
        "                regulatory_data.get('clusters', []),\n",
        "                policy_data.get('clusters', []),\n",
        "                similarity_matrix\n",
        "            ),\n",
        "            'compliance_score': self._calculate_overall_compliance_score(similarity_matrix)\n",
        "        }\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _find_detailed_matches(self, regulatory_metadata: List[Dict],\n",
        "                               policy_metadata: List[Dict],\n",
        "                               similarity_matrix: np.ndarray) -> List[Dict]:\n",
        "        \"\"\"Find detailed matches with context and confidence\"\"\"\n",
        "        matches = []\n",
        "\n",
        "        if len(regulatory_metadata) == 0 or similarity_matrix.size == 0:\n",
        "            return matches\n",
        "\n",
        "        for reg_idx, reg_item in enumerate(regulatory_metadata):\n",
        "            reg_scores = similarity_matrix[reg_idx]\n",
        "\n",
        "            # Find top matches above minimum threshold\n",
        "            if len(policy_metadata) == 0:\n",
        "                best_score = 0.0\n",
        "                valid_matches = []\n",
        "            else:\n",
        "                valid_matches = [(idx, score) for idx, score in enumerate(reg_scores)\n",
        "                                 if score >= self.thresholds['weak_coverage']]\n",
        "                valid_matches.sort(key=lambda x: x[1], reverse=True)\n",
        "                best_score = valid_matches[0][1] if valid_matches else 0.0\n",
        "\n",
        "            match_details = {\n",
        "                'regulatory_item': reg_item, # Contains 'text', 'source', 'type'\n",
        "                'regulatory_index': reg_idx,\n",
        "                'regulatory_source_doc': reg_item.get('source', 'N/A'), # Added source for clarity\n",
        "                'matches': [],\n",
        "                'best_score': float(best_score), # Ensure float for JSON serialization\n",
        "                'coverage_level': self._determine_coverage_level(best_score)\n",
        "            }\n",
        "\n",
        "            # Add top 5 matches (or fewer if not enough valid_matches)\n",
        "            for pol_idx, score in valid_matches[:5]:\n",
        "                policy_item = policy_metadata[pol_idx]\n",
        "\n",
        "                match_details['matches'].append({\n",
        "                    'policy_item': policy_item, # Contains 'text', 'source', 'type'\n",
        "                    'policy_index': pol_idx,\n",
        "                    'policy_source_doc': policy_item.get('source', 'N/A'), # Added source for clarity\n",
        "                    'similarity_score': float(score),\n",
        "                    'coverage_level': self._determine_coverage_level(score),\n",
        "                    'semantic_overlap': self._calculate_semantic_overlap(\n",
        "                        reg_item, policy_item # These should contain the actual text/metadata for term extraction if implemented\n",
        "                    )\n",
        "                })\n",
        "\n",
        "            matches.append(match_details)\n",
        "\n",
        "        return matches\n",
        "\n",
        "    def _analyze_coverage(self, regulatory_metadata: List[Dict],\n",
        "                          policy_metadata: List[Dict],\n",
        "                          similarity_matrix: np.ndarray) -> Dict:\n",
        "        \"\"\"Analyze overall coverage statistics\"\"\"\n",
        "        if similarity_matrix.size == 0 or len(regulatory_metadata) == 0:\n",
        "            return {'total_requirements': 0, 'total_policies': 0, 'coverage_stats': {}, 'average_best_match_score': 0.0, 'coverage_distribution': {}}\n",
        "\n",
        "        max_scores = np.max(similarity_matrix, axis=1)\n",
        "\n",
        "        coverage_stats = {}\n",
        "        for level, threshold in self.thresholds.items():\n",
        "            covered_count = np.sum(max_scores >= threshold)\n",
        "            coverage_stats[level] = {\n",
        "                'count': int(covered_count),\n",
        "                'percentage': float(covered_count / len(regulatory_metadata) * 100) if regulatory_metadata else 0.0\n",
        "            }\n",
        "\n",
        "        return {\n",
        "            'total_requirements': len(regulatory_metadata),\n",
        "            'total_policies': len(policy_metadata),\n",
        "            'coverage_stats': coverage_stats,\n",
        "            'average_best_match_score': float(np.mean(max_scores)) if len(max_scores) > 0 else 0.0,\n",
        "            'coverage_distribution': self._analyze_coverage_distribution(max_scores)\n",
        "        }\n",
        "\n",
        "    def _perform_gap_analysis(self, regulatory_metadata: List[Dict],\n",
        "                              policy_metadata: List[Dict],\n",
        "                              similarity_matrix: np.ndarray) -> Dict:\n",
        "        \"\"\"Perform detailed gap analysis\"\"\"\n",
        "        gaps = {\n",
        "            'critical_gaps': [],\n",
        "            'significant_gaps': [],\n",
        "            'minor_gaps': [],\n",
        "            'gap_categories': defaultdict(list),\n",
        "            'recommendations': []\n",
        "        }\n",
        "\n",
        "        if similarity_matrix.size == 0 or len(regulatory_metadata) == 0:\n",
        "            return gaps\n",
        "\n",
        "        for reg_idx, reg_item in enumerate(regulatory_metadata):\n",
        "            best_score = np.max(similarity_matrix[reg_idx]) if similarity_matrix.shape[1] > 0 else 0.0\n",
        "\n",
        "            gap_info = {\n",
        "                'regulatory_requirement': reg_item, # Contains 'text', 'source', 'type'\n",
        "                'regulatory_source_doc': reg_item.get('source', 'N/A'), # Added source for clarity\n",
        "                'best_match_score': float(best_score),\n",
        "                'gap_severity': self._calculate_gap_severity(best_score),\n",
        "                'requirement_type': reg_item.get('type', 'unknown'),\n",
        "                'key_terms': reg_item.get('key_terms', []), # Assuming key_terms can be extracted or added\n",
        "                'recommendations': self._generate_targeted_recommendations(reg_item, best_score)\n",
        "            }\n",
        "\n",
        "            # Categorize gaps\n",
        "            if best_score < self.thresholds['weak_coverage']:\n",
        "                gaps['critical_gaps'].append(gap_info)\n",
        "            elif best_score < self.thresholds['partial_coverage']:\n",
        "                gaps['significant_gaps'].append(gap_info)\n",
        "            elif best_score < self.thresholds['strong_coverage']:\n",
        "                gaps['minor_gaps'].append(gap_info)\n",
        "\n",
        "            # Categorize by requirement type (if available in metadata)\n",
        "            req_type = reg_item.get('type', 'unknown')\n",
        "            if best_score < self.thresholds['partial_coverage']: # Consider gaps below 'partial coverage' for category analysis\n",
        "                gaps['gap_categories'][req_type].append(gap_info)\n",
        "\n",
        "        # Generate high-level recommendations\n",
        "        gaps['recommendations'] = self._generate_strategic_recommendations(gaps)\n",
        "\n",
        "        return gaps\n",
        "\n",
        "    def _determine_coverage_level(self, score: float) -> str:\n",
        "        \"\"\"Determine coverage level based on similarity score\"\"\"\n",
        "        if score >= self.thresholds['exact_match']:\n",
        "            return 'excellent'\n",
        "        elif score >= self.thresholds['strong_coverage']:\n",
        "            return 'good'\n",
        "        elif score >= self.thresholds['partial_coverage']:\n",
        "            return 'partial'\n",
        "        elif score >= self.thresholds['weak_coverage']:\n",
        "            return 'weak'\n",
        "        else:\n",
        "            return 'none'\n",
        "\n",
        "    def _calculate_semantic_overlap(self, reg_item: Dict, policy_item: Dict) -> Dict:\n",
        "        \"\"\"Calculate semantic overlap between items\n",
        "        NOTE: This currently uses placeholder for key term extraction.\n",
        "        To make this fully functional, key_terms need to be extracted and added\n",
        "        to the metadata of each chunk/requirement in TextProcessor.\n",
        "        \"\"\"\n",
        "        # Placeholder - needs actual key term extraction from TextProcessor or here\n",
        "        reg_terms = set(reg_item.get('key_terms', []))\n",
        "        pol_terms = set(policy_item.get('key_terms', []))\n",
        "\n",
        "        if not reg_terms and not pol_terms:\n",
        "            return {'overlap_score': 0.0, 'common_terms': [], 'missing_terms': []}\n",
        "\n",
        "        common_terms = list(reg_terms.intersection(pol_terms))\n",
        "        overlap_score = len(common_terms) / len(reg_terms) if reg_terms else 0.0\n",
        "        missing_terms = list(reg_terms - pol_terms) # Terms in regulation not found in policy\n",
        "\n",
        "        return {\n",
        "            'overlap_score': float(overlap_score), # Ensure float for JSON\n",
        "            'common_terms': common_terms,\n",
        "            'missing_terms': missing_terms\n",
        "        }\n",
        "\n",
        "    def _calculate_gap_severity(self, score: float) -> str:\n",
        "        \"\"\"Calculate gap severity with more nuanced levels\"\"\"\n",
        "        if score < 0.20:\n",
        "            return \"Critical\"\n",
        "        elif score < 0.35:\n",
        "            return \"High\"\n",
        "        elif score < 0.50:\n",
        "            return \"Medium\"\n",
        "        elif score < 0.70:\n",
        "            return \"Low\"\n",
        "        else:\n",
        "            return \"Minimal\"\n",
        "\n",
        "    def _generate_targeted_recommendations(self, reg_item: Dict, score: float) -> List[str]:\n",
        "        \"\"\"Generate targeted recommendations based on requirement analysis\"\"\"\n",
        "        recommendations = []\n",
        "        # Access the 'text' key safely and truncate for display\n",
        "        reg_item_text_excerpt = reg_item.get('text', 'N/A')[:50] + '...'\n",
        "\n",
        "        key_terms = reg_item.get('key_terms', []) # This would need to be extracted\n",
        "\n",
        "        if score < self.thresholds['weak_coverage']:\n",
        "            recommendations.append(f\"Create new policy section addressing the regulatory requirement: '{reg_item_text_excerpt}' (Source: {reg_item.get('source', 'N/A')}).\")\n",
        "            if key_terms:\n",
        "                recommendations.append(f\"Focus on key areas: {', '.join(key_terms[:5])}\")\n",
        "        elif score < self.thresholds['partial_coverage']:\n",
        "            recommendations.append(f\"Enhance existing policy to better address the regulatory requirement: '{reg_item_text_excerpt}' (Source: {reg_item.get('source', 'N/A')}).\")\n",
        "            recommendations.append(\"Review policy language for alignment with regulatory terminology.\")\n",
        "        elif score < self.thresholds['strong_coverage']:\n",
        "            recommendations.append(f\"Minor policy adjustments needed for full compliance with this requirement: '{reg_item_text_excerpt}' (Source: {reg_item.get('source', 'N/A')}).\")\n",
        "\n",
        "        recommendations.append(\"Engage legal/compliance team for detailed review.\")\n",
        "        return recommendations\n",
        "\n",
        "    def _analyze_coverage_distribution(self, scores: np.ndarray) -> Dict:\n",
        "        \"\"\"Analyze the distribution of coverage scores\"\"\"\n",
        "        if len(scores) == 0:\n",
        "            return {}\n",
        "\n",
        "        return {\n",
        "            'min_score': float(np.min(scores)),\n",
        "            'max_score': float(np.max(scores)),\n",
        "            'median_score': float(np.median(scores)),\n",
        "            'std_dev': float(np.std(scores)),\n",
        "            'quartiles': {\n",
        "                'q1': float(np.percentile(scores, 25)),\n",
        "                'q2': float(np.percentile(scores, 50)),\n",
        "                'q3': float(np.percentile(scores, 75))\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def _analyze_semantic_clusters(self, reg_clusters: List[Dict],\n",
        "                                   pol_clusters: List[Dict],\n",
        "                                   similarity_matrix: np.ndarray) -> Dict:\n",
        "        \"\"\"Analyze semantic clusters for better insights\"\"\"\n",
        "        cluster_analysis = {\n",
        "            'regulatory_clusters': len(reg_clusters),\n",
        "            'policy_clusters': len(pol_clusters),\n",
        "            'cluster_coverage': []\n",
        "        }\n",
        "\n",
        "        if similarity_matrix.size == 0 or similarity_matrix.shape[1] == 0:\n",
        "            return cluster_analysis\n",
        "\n",
        "        for reg_cluster in reg_clusters:\n",
        "            cluster_items = reg_cluster['items']\n",
        "            if not cluster_items:\n",
        "                continue\n",
        "\n",
        "            # Calculate coverage for this cluster\n",
        "            # Ensure indices are within bounds of similarity_matrix\n",
        "            valid_indices = [idx for idx in cluster_items if idx < similarity_matrix.shape[0]]\n",
        "            if not valid_indices:\n",
        "                continue\n",
        "\n",
        "            cluster_scores = similarity_matrix[valid_indices]\n",
        "            # Max along axis=1 means for each regulatory item, find its best match in policy\n",
        "            avg_coverage = np.mean(np.max(cluster_scores, axis=1)) if cluster_scores.size > 0 else 0.0\n",
        "\n",
        "            cluster_analysis['cluster_coverage'].append({\n",
        "                'cluster_id': reg_cluster['cluster_id'],\n",
        "                'size': reg_cluster['size'],\n",
        "                'average_coverage': float(avg_coverage),\n",
        "                'coverage_level': self._determine_coverage_level(avg_coverage)\n",
        "            })\n",
        "\n",
        "        return cluster_analysis\n",
        "\n",
        "    def _calculate_overall_compliance_score(self, similarity_matrix: np.ndarray) -> Dict:\n",
        "        \"\"\"Calculate overall compliance score with multiple metrics\"\"\"\n",
        "        if similarity_matrix.size == 0 or similarity_matrix.shape[0] == 0:\n",
        "            return {'overall_score': 0.0, 'grade': 'F', 'metrics': {}}\n",
        "\n",
        "        max_scores = np.max(similarity_matrix, axis=1)\n",
        "\n",
        "        # Weighted scoring system\n",
        "        weights = {\n",
        "            'excellent': 1.0,\n",
        "            'good': 0.8,\n",
        "            'partial': 0.5,\n",
        "            'weak': 0.2,\n",
        "            'none': 0.0\n",
        "        }\n",
        "\n",
        "        weighted_score = 0.0\n",
        "        for score in max_scores:\n",
        "            level = self._determine_coverage_level(score)\n",
        "            weighted_score += weights[level]\n",
        "\n",
        "        overall_score = weighted_score / len(max_scores) if len(max_scores) > 0 else 0.0\n",
        "\n",
        "        # Assign letter grade\n",
        "        if overall_score >= 0.9:\n",
        "            grade = 'A'\n",
        "        elif overall_score >= 0.8:\n",
        "            grade = 'B'\n",
        "        elif overall_score >= 0.7:\n",
        "            grade = 'C'\n",
        "        elif overall_score >= 0.6:\n",
        "            grade = 'D'\n",
        "        else:\n",
        "            grade = 'F'\n",
        "\n",
        "        return {\n",
        "            'overall_score': float(overall_score), # Ensure float\n",
        "            'grade': grade,\n",
        "            'metrics': {\n",
        "                'average_similarity': float(np.mean(max_scores)),\n",
        "                'median_similarity': float(np.median(max_scores)),\n",
        "                'requirements_above_70': int(np.sum(max_scores >= 0.7)),\n",
        "                'requirements_below_30': int(np.sum(max_scores < 0.3))\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def _generate_strategic_recommendations(self, gaps: Dict) -> List[str]:\n",
        "        \"\"\"Generate strategic recommendations based on gap analysis\"\"\"\n",
        "        recommendations = []\n",
        "\n",
        "        critical_count = len(gaps['critical_gaps'])\n",
        "        significant_count = len(gaps['significant_gaps'])\n",
        "        minor_count = len(gaps['minor_gaps'])\n",
        "\n",
        "        if critical_count > 0:\n",
        "            recommendations.append(f\"PRIORITY: Address {critical_count} critical compliance gaps immediately to mitigate high legal and operational risks.\")\n",
        "\n",
        "        if significant_count > 0:\n",
        "            recommendations.append(f\"Address {significant_count} significant gaps within the next review cycle to improve compliance posture.\")\n",
        "\n",
        "        # Category-specific recommendations based on 'gap_categories'\n",
        "        gap_categories = gaps['gap_categories']\n",
        "        # Note: 'obligations' and 'prohibitions' types would need explicit extraction in TextProcessor\n",
        "        # For now, we'll check for their existence.\n",
        "        if 'obligations' in gap_categories and len(gap_categories['obligations']) > 0:\n",
        "            recommendations.append(f\"Focus on mandatory obligation compliance for {len(gap_categories['obligations'])} items – these carry the highest legal risk.\")\n",
        "\n",
        "        if 'prohibitions' in gap_categories and len(gap_categories['prohibitions']) > 0:\n",
        "            recommendations.append(f\"Review prohibition compliance for {len(gap_categories['prohibitions'])} items – ensure clear policy restrictions are in place.\")\n",
        "\n",
        "        if minor_count > 0:\n",
        "             recommendations.append(f\"Monitor {minor_count} minor compliance gaps proactively; while less severe, they can accumulate.\")\n",
        "\n",
        "\n",
        "        # General recommendations if no specific high-priority gaps were found, or in addition to\n",
        "        if not recommendations or (critical_count + significant_count) == 0:\n",
        "             recommendations.append(\"Implement continuous monitoring system for regulatory changes and regular policy reviews.\")\n",
        "             recommendations.append(\"Consider cross-functional workshops involving legal, compliance, and operational teams to align policies with regulatory intent.\")\n",
        "\n",
        "\n",
        "        # Final fallback recommendation if no specific recommendations generated (e.g., if all documents are perfectly compliant or empty)\n",
        "        if not recommendations:\n",
        "            recommendations.append(\"Compliance appears to be strong based on current analysis. Maintain regular reviews and proactive monitoring for future changes.\")\n",
        "\n",
        "        return recommendations\n"
      ],
      "metadata": {
        "id": "JaUNS_rz8Vqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 5. ComplianceAnalyzer\n",
        " Main orchestrator that coordinates the entire compliance analysis pipeline.\n",
        "\n"
      ],
      "metadata": {
        "id": "7i2zYo7Z9R6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ComplianceAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.doc_processor = DocumentProcessor()\n",
        "        self.text_processor = TextProcessor()\n",
        "        self.embedding_gen = EmbeddingGenerator()\n",
        "        self.similarity_analyzer = SimilarityAnalyzer(self.embedding_gen)\n",
        "\n",
        "    def analyze_compliance(self, policy_folder: str, regulatory_folder: str, output_path: str):\n",
        "        \"\"\"Main compliance analysis pipeline\"\"\"\n",
        "        print(\"Step 1: Processing documents...\")\n",
        "\n",
        "        # Process policy documents\n",
        "        policy_docs = self.doc_processor.process_documents(\n",
        "            policy_folder, doc_type=\"policy\"\n",
        "        )\n",
        "\n",
        "        # Process regulatory documents\n",
        "        regulatory_docs = self.doc_processor.process_documents(\n",
        "            regulatory_folder, doc_type=\"regulatory\"\n",
        "        )\n",
        "\n",
        "        print(f\"Found {len(policy_docs)} policy documents and {len(regulatory_docs)} regulatory documents\")\n",
        "\n",
        "        print(\"Step 2: Extracting requirements...\")\n",
        "\n",
        "        # Extract and chunk policy content\n",
        "        policy_chunks = []\n",
        "        for doc in policy_docs:\n",
        "            chunks = self.text_processor.chunk_document(doc['text'])\n",
        "            for chunk in chunks:\n",
        "                policy_chunks.append({\n",
        "                    'text': chunk,\n",
        "                    'source': doc['filename'], # Source file of the policy\n",
        "                    'type': 'policy'\n",
        "                })\n",
        "\n",
        "        # Extract regulatory requirements\n",
        "        regulatory_requirements = []\n",
        "        for doc in regulatory_docs:\n",
        "            requirements = self.text_processor.extract_requirements(doc['text'])\n",
        "            for req in requirements:\n",
        "                # Add 'source' to regulatory_requirements for detailed match reporting\n",
        "                regulatory_requirements.append({\n",
        "                    'text': req,\n",
        "                    'source': doc['filename'], # Source file of the regulation\n",
        "                    'type': 'regulatory'\n",
        "                })\n",
        "\n",
        "        print(f\"Extracted {len(policy_chunks)} policy chunks and {len(regulatory_requirements)} regulatory requirements\")\n",
        "\n",
        "        print(\"Step 3: Generating embeddings...\")\n",
        "\n",
        "        # Generate embeddings\n",
        "        policy_texts = [chunk['text'] for chunk in policy_chunks]\n",
        "        regulatory_texts = [req['text'] for req in regulatory_requirements]\n",
        "\n",
        "        # Handle cases where there are no texts to embed\n",
        "        policy_embeddings = self.embedding_gen.generate_contextual_embeddings(policy_texts)\n",
        "        regulatory_embeddings = self.embedding_gen.generate_contextual_embeddings(regulatory_texts)\n",
        "\n",
        "        print(\"Step 4: Analyzing similarities...\")\n",
        "\n",
        "        # Prepare data for SimilarityAnalyzer\n",
        "        policy_data = {\n",
        "            'embeddings': policy_embeddings,\n",
        "            'metadata': policy_chunks,\n",
        "            'clusters': self.embedding_gen.create_hierarchical_index(policy_embeddings, policy_chunks).get('clusters', [])\n",
        "        }\n",
        "        regulatory_data = {\n",
        "            'embeddings': regulatory_embeddings,\n",
        "            'metadata': regulatory_requirements,\n",
        "            'clusters': self.embedding_gen.create_hierarchical_index(regulatory_embeddings, regulatory_requirements).get('clusters', [])\n",
        "        }\n",
        "\n",
        "        # Let SimilarityAnalyzer handle similarity and analysis\n",
        "        results = self.similarity_analyzer.comprehensive_similarity_analysis(policy_data, regulatory_data)\n",
        "\n",
        "        # Flatten gaps for reporting (as _perform_gap_analysis already categorizes them)\n",
        "        gaps = []\n",
        "        for gap_type in ['critical_gaps', 'significant_gaps', 'minor_gaps']:\n",
        "            gaps.extend(results['gap_analysis'].get(gap_type, []))\n",
        "\n",
        "        print(\"Step 5: Generating report...\")\n",
        "\n",
        "        report = self.generate_report(results, policy_docs, regulatory_docs) # Pass full results for more data\n",
        "        self.save_results(report, output_path) # Simplified save, report contains all info\n",
        "\n",
        "        return report, results\n",
        "\n",
        "    def generate_report(self, analysis_results: Dict, policy_docs: List[Dict], regulatory_docs: List[Dict]) -> Dict:\n",
        "        \"\"\"Generate comprehensive compliance report\"\"\"\n",
        "        matches = analysis_results.get('detailed_matches', [])\n",
        "        gaps = []\n",
        "        for gap_type in ['critical_gaps', 'significant_gaps', 'minor_gaps']:\n",
        "            gaps.extend(analysis_results['gap_analysis'].get(gap_type, []))\n",
        "\n",
        "        total_requirements = len(analysis_results['regulatory_data']['metadata']) if 'regulatory_data' in analysis_results else len(matches) # Use original count\n",
        "\n",
        "        # Calculate covered requirements based on 'good' or 'excellent' coverage\n",
        "        covered_requirements = sum(\n",
        "            1 for match in matches\n",
        "            if match.get('best_score', 0.0) >= self.similarity_analyzer.thresholds['strong_coverage'] # Using best_score\n",
        "        )\n",
        "        coverage_percentage = (covered_requirements / total_requirements) * 100 if total_requirements else 0.0\n",
        "\n",
        "        report = {\n",
        "            'analysis_date': datetime.now().isoformat(),\n",
        "            'summary': {\n",
        "                'total_policy_documents': len(policy_docs),\n",
        "                'total_regulatory_documents': len(regulatory_docs),\n",
        "                'total_requirements_analyzed': total_requirements,\n",
        "                'requirements_covered_by_good_or_excellent_match': covered_requirements,\n",
        "                'coverage_percentage': float(coverage_percentage), # Ensure float\n",
        "                'total_gaps_identified': len(gaps),\n",
        "                'overall_compliance_score': analysis_results['compliance_score'].get('overall_score', 0.0),\n",
        "                'compliance_grade': analysis_results['compliance_score'].get('grade', 'F')\n",
        "            },\n",
        "            'gap_severity_breakdown': self.get_gap_severity_breakdown(gaps),\n",
        "            'high_level_recommendations': analysis_results['gap_analysis'].get('recommendations', []), # Use recommendations from analyzer\n",
        "            'detailed_analysis': {\n",
        "                'matches': matches, # Already includes regulatory_item and details\n",
        "                'gaps': gaps\n",
        "            }\n",
        "        }\n",
        "        return report\n",
        "\n",
        "    def get_gap_severity_breakdown(self, gaps: List[Dict]) -> Dict:\n",
        "        \"\"\"Return a breakdown of gap severities.\"\"\"\n",
        "        from collections import Counter\n",
        "        severities = [gap.get('gap_severity', 'Unknown') for gap in gaps]\n",
        "        return dict(Counter(severities))\n",
        "\n",
        "    def get_high_level_recommendations(self, gaps: List[Dict]) -> List[str]:\n",
        "        \"\"\"Deprecated: High-level recommendations are now generated by SimilarityAnalyzer._generate_strategic_recommendations.\"\"\"\n",
        "        # This method is now effectively replaced by the _generate_strategic_recommendations in SimilarityAnalyzer.\n",
        "        # Keeping it for compatibility if something else in the code still calls it, but its logic should be moved.\n",
        "        # For simplicity in this fix, I'll return an empty list and ensure the report uses the analyzer's recommendations.\n",
        "        return []\n",
        "\n",
        "    def save_results(self, report: Dict, output_path: str):\n",
        "        \"\"\"Save analysis results to files\"\"\"\n",
        "        # Ensure output directory exists\n",
        "        os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "        # Save JSON report\n",
        "        report_filename = os.path.join(output_path, \"compliance_report.json\")\n",
        "        with open(report_filename, 'w') as f:\n",
        "            json.dump(report, f, indent=2)\n",
        "        print(f\"JSON report saved to {report_filename}\")\n",
        "\n",
        "        # Save Excel summary\n",
        "        excel_filename = os.path.join(output_path, \"compliance_analysis.xlsx\")\n",
        "        self.create_excel_report(report, excel_filename)\n",
        "        print(f\"Excel report saved to {excel_filename}\")\n",
        "\n",
        "    def create_excel_report(self, report: Dict, filename: str):\n",
        "        \"\"\"Create Excel report with multiple sheets\"\"\"\n",
        "        with pd.ExcelWriter(filename, engine='xlsxwriter') as writer:\n",
        "            # Summary sheet\n",
        "            summary_data = []\n",
        "            for key, value in report['summary'].items():\n",
        "                summary_data.append({'Metric': key.replace('_', ' ').title(), 'Value': value})\n",
        "\n",
        "            pd.DataFrame(summary_data).to_excel(\n",
        "                writer, sheet_name='Summary', index=False\n",
        "            )\n",
        "\n",
        "            # Gaps sheet\n",
        "            gaps_data = []\n",
        "            for gap in report['detailed_analysis']['gaps']:\n",
        "                reg_req_text = gap['regulatory_requirement'].get('text', 'N/A')\n",
        "                gaps_data.append({\n",
        "                    'Regulatory Requirement (Excerpt)': reg_req_text[:200] + '...' if len(reg_req_text) > 200 else reg_req_text,\n",
        "                    'Regulatory Source Document': gap.get('regulatory_source_doc', 'N/A'), # Explicitly added\n",
        "                    'Best Match Score': gap.get('best_match_score', 0.0),\n",
        "                    'Gap Severity': gap.get('gap_severity', 'Unknown'),\n",
        "                    'Recommendations': \"; \".join(gap.get('recommendations', []))\n",
        "                })\n",
        "            pd.DataFrame(gaps_data).to_excel(\n",
        "                writer, sheet_name='Gaps', index=False\n",
        "            )\n",
        "\n",
        "            # Matches sheet\n",
        "            matches_data = []\n",
        "            for match_detail in report['detailed_analysis']['matches']:\n",
        "                # The primary regulatory requirement\n",
        "                reg_item_text = match_detail['regulatory_item'].get('text', 'N/A')\n",
        "                reg_item_source = match_detail['regulatory_item'].get('source', 'N/A') # Ensure source is pulled from reg_item\n",
        "\n",
        "                # Add a row for the regulatory requirement itself, with its best match\n",
        "                if match_detail['matches']: # If there's at least one match\n",
        "                    best_pol_match = match_detail['matches'][0] # Top match\n",
        "                    pol_item_text = best_pol_match['policy_item'].get('text', 'N/A')\n",
        "                    pol_item_source = best_pol_match['policy_item'].get('source', 'N/A') # Ensure source is pulled from pol_item\n",
        "                    matches_data.append({\n",
        "                        'Regulatory Requirement (Excerpt)': reg_item_text[:200] + '...' if len(reg_item_text) > 200 else reg_item_text,\n",
        "                        'Regulatory Source Document': reg_item_source, # Explicitly added\n",
        "                        'Best Policy Match (Excerpt)': pol_item_text[:200] + '...' if len(pol_item_text) > 200 else pol_item_text,\n",
        "                        'Policy Source Document': pol_item_source, # Explicitly added\n",
        "                        'Best Similarity Score': best_pol_match.get('similarity_score', 0.0),\n",
        "                        'Coverage Level': best_pol_match.get('coverage_level', 'none')\n",
        "                    })\n",
        "                else: # No matches found\n",
        "                    matches_data.append({\n",
        "                        'Regulatory Requirement (Excerpt)': reg_item_text[:200] + '...' if len(reg_item_text) > 200 else reg_item_text,\n",
        "                        'Regulatory Source Document': reg_item_source, # Explicitly added\n",
        "                        'Best Policy Match (Excerpt)': 'No direct policy match',\n",
        "                        'Policy Source Document': 'N/A',\n",
        "                        'Best Similarity Score': 0.0,\n",
        "                        'Coverage Level': 'none'\n",
        "                    })\n",
        "            pd.DataFrame(matches_data).to_excel(\n",
        "                writer, sheet_name='Matches', index=False\n",
        "            )\n",
        "\n",
        "            # Recommendations sheet\n",
        "            recommendations_data = [{'Recommendation': rec} for rec in report['high_level_recommendations']]\n",
        "            pd.DataFrame(recommendations_data).to_excel(\n",
        "                writer, sheet_name='High-Level Recommendations', index=False\n",
        "            )\n"
      ],
      "metadata": {
        "id": "-YocJx8l8erp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    analyzer = ComplianceAnalyzer()\n",
        "    report, matches = analyzer.analyze_compliance(\n",
        "        policy_folder=\"./policies\",\n",
        "        regulatory_folder=\"./regulations\",\n",
        "        output_path=\"./results\"\n",
        "    )\n",
        "    print(f\"Analysis complete! Coverage: {report['summary']['coverage_percentage']:.1f}%\")\n",
        "    print(f\"Gaps identified: {len(gaps)}\")\n"
      ],
      "metadata": {
        "id": "fZsTCeVB7dbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Technical Features\n",
        "\n",
        "### Similarity Thresholds\n",
        "- **Exact Match (0.85)**: Very high similarity indicating strong alignment\n",
        "- **Strong Coverage (0.70)**: Good coverage with minor gaps\n",
        "- **Partial Coverage (0.50)**: Some coverage but significant improvements needed\n",
        "- **Weak Coverage (0.30)**: Minimal coverage requiring attention\n",
        "\n",
        "### Gap Analysis Categories\n",
        "- **Critical Gaps**: Requirements with similarity scores below 0.30\n",
        "- **Significant Gaps**: Requirements with scores between 0.30-0.50\n",
        "- **Minor Gaps**: Requirements with scores between 0.50-0.70\n",
        "\n",
        "### Machine Learning Components\n",
        "- **Sentence Transformers**: For generating contextual embeddings\n",
        "- **FAISS**: For efficient similarity search and indexing\n",
        "- **K-means Clustering**: For semantic grouping of content\n",
        "- **spaCy**: For natural language processing and requirement extraction\n",
        "\n",
        "### Output Capabilities\n",
        "- Detailed similarity matrices\n",
        "- Coverage statistics and distributions\n",
        "- Categorized gap analysis with recommendations\n",
        "- Compliance scoring with letter grades\n",
        "- Semantic cluster analysis\n",
        "- Strategic recommendations for improvement\n",
        "\n",
        "## Use Cases\n",
        "- **Regulatory Compliance Audits**: Compare internal policies against regulatory frameworks\n",
        "- **Policy Gap Analysis**: Identify areas where organizational policies don't meet regulatory requirements\n",
        "- **Compliance Monitoring**: Track compliance coverage over time\n",
        "- **Risk Assessment**: Prioritize compliance efforts based on gap severity\n",
        "- **Policy Development**: Guide creation of new policies to address identified gaps"
      ],
      "metadata": {
        "id": "5-bn62Fq71O9"
      }
    }
  ]
}